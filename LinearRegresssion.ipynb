{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model complexity and Bias Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up pandas / sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "import pandas as pd \n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from  sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "print sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module sklearn.metrics.regression in sklearn.metrics:\n",
      "\n",
      "NAME\n",
      "    sklearn.metrics.regression - Metrics to assess performance on regression task\n",
      "\n",
      "FILE\n",
      "    c:\\anaconda2\\lib\\site-packages\\sklearn\\metrics\\regression.py\n",
      "\n",
      "DESCRIPTION\n",
      "    Functions named as ``*_score`` return a scalar value to maximize: the higher\n",
      "    the better\n",
      "    \n",
      "    Function named as ``*_error`` or ``*_loss`` return a scalar value to minimize:\n",
      "    the lower the better\n",
      "\n",
      "FUNCTIONS\n",
      "    explained_variance_score(y_true, y_pred, sample_weight=None, multioutput='uniform_average')\n",
      "        Explained variance regression score function\n",
      "        \n",
      "        Best possible score is 1.0, lower values are worse.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <explained_variance_score>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape = (n_samples), optional\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : string in ['raw_values', 'uniform_average',                 'variance_weighted'] or array-like of shape (n_outputs)\n",
      "            Defines aggregating of multiple output scores.\n",
      "            Array-like value defines weights used to average scores.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of scores in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Scores of all outputs are averaged with uniform weight.\n",
      "        \n",
      "            'variance_weighted' :\n",
      "                Scores of all outputs are averaged, weighted by the variances\n",
      "                of each individual output.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float or ndarray of floats\n",
      "            The explained variance or ndarray if 'multioutput' is 'raw_values'.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is not a symmetric function.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import explained_variance_score\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> explained_variance_score(y_true, y_pred)  # doctest: +ELLIPSIS\n",
      "        0.957...\n",
      "        >>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
      "        >>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
      "        >>> explained_variance_score(y_true, y_pred, multioutput='uniform_average')\n",
      "        ... # doctest: +ELLIPSIS\n",
      "        0.983...\n",
      "    \n",
      "    mean_absolute_error(y_true, y_pred, sample_weight=None, multioutput='uniform_average')\n",
      "        Mean absolute error regression loss\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mean_absolute_error>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape = (n_samples), optional\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : string in ['raw_values', 'uniform_average']\n",
      "            or array-like of shape (n_outputs)\n",
      "            Defines aggregating of multiple output values.\n",
      "            Array-like value defines weights used to average errors.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Errors of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or ndarray of floats\n",
      "            If multioutput is 'raw_values', then mean absolute error is returned\n",
      "            for each output separately.\n",
      "            If multioutput is 'uniform_average' or an ndarray of weights, then the\n",
      "            weighted average of all output errors is returned.\n",
      "        \n",
      "            MAE output is non-negative floating point. The best value is 0.0.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import mean_absolute_error\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> mean_absolute_error(y_true, y_pred)\n",
      "        0.5\n",
      "        >>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
      "        >>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
      "        >>> mean_absolute_error(y_true, y_pred)\n",
      "        0.75\n",
      "        >>> mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
      "        array([ 0.5,  1. ])\n",
      "        >>> mean_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])\n",
      "        ... # doctest: +ELLIPSIS\n",
      "        0.849...\n",
      "    \n",
      "    mean_squared_error(y_true, y_pred, sample_weight=None, multioutput='uniform_average')\n",
      "        Mean squared error regression loss\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mean_squared_error>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape = (n_samples), optional\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : string in ['raw_values', 'uniform_average']\n",
      "            or array-like of shape (n_outputs)\n",
      "            Defines aggregating of multiple output values.\n",
      "            Array-like value defines weights used to average errors.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Errors of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or ndarray of floats\n",
      "            A non-negative floating point value (the best value is 0.0), or an\n",
      "            array of floating point values, one for each individual target.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import mean_squared_error\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> mean_squared_error(y_true, y_pred)\n",
      "        0.375\n",
      "        >>> y_true = [[0.5, 1],[-1, 1],[7, -6]]\n",
      "        >>> y_pred = [[0, 2],[-1, 2],[8, -5]]\n",
      "        >>> mean_squared_error(y_true, y_pred)  # doctest: +ELLIPSIS\n",
      "        0.708...\n",
      "        >>> mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
      "        ... # doctest: +ELLIPSIS\n",
      "        array([ 0.416...,  1.        ])\n",
      "        >>> mean_squared_error(y_true, y_pred, multioutput=[0.3, 0.7])\n",
      "        ... # doctest: +ELLIPSIS\n",
      "        0.824...\n",
      "    \n",
      "    mean_squared_log_error(y_true, y_pred, sample_weight=None, multioutput='uniform_average')\n",
      "        Mean squared logarithmic error regression loss\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mean_squared_log_error>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape = (n_samples), optional\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : string in ['raw_values', 'uniform_average']             or array-like of shape = (n_outputs)\n",
      "        \n",
      "            Defines aggregating of multiple output values.\n",
      "            Array-like value defines weights used to average errors.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors when the input is of multioutput\n",
      "                format.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Errors of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or ndarray of floats\n",
      "            A non-negative floating point value (the best value is 0.0), or an\n",
      "            array of floating point values, one for each individual target.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import mean_squared_log_error\n",
      "        >>> y_true = [3, 5, 2.5, 7]\n",
      "        >>> y_pred = [2.5, 5, 4, 8]\n",
      "        >>> mean_squared_log_error(y_true, y_pred)  # doctest: +ELLIPSIS\n",
      "        0.039...\n",
      "        >>> y_true = [[0.5, 1], [1, 2], [7, 6]]\n",
      "        >>> y_pred = [[0.5, 2], [1, 2.5], [8, 8]]\n",
      "        >>> mean_squared_log_error(y_true, y_pred)  # doctest: +ELLIPSIS\n",
      "        0.044...\n",
      "        >>> mean_squared_log_error(y_true, y_pred, multioutput='raw_values')\n",
      "        ... # doctest: +ELLIPSIS\n",
      "        array([ 0.004...,  0.083...])\n",
      "        >>> mean_squared_log_error(y_true, y_pred, multioutput=[0.3, 0.7])\n",
      "        ... # doctest: +ELLIPSIS\n",
      "        0.060...\n",
      "    \n",
      "    median_absolute_error(y_true, y_pred)\n",
      "        Median absolute error regression loss\n",
      "        \n",
      "        Read more in the :ref:`User Guide <median_absolute_error>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape = (n_samples)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape = (n_samples)\n",
      "            Estimated target values.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float\n",
      "            A positive floating point value (the best value is 0.0).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import median_absolute_error\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> median_absolute_error(y_true, y_pred)\n",
      "        0.5\n",
      "    \n",
      "    r2_score(y_true, y_pred, sample_weight=None, multioutput='uniform_average')\n",
      "        R^2 (coefficient of determination) regression score function.\n",
      "        \n",
      "        Best possible score is 1.0 and it can be negative (because the\n",
      "        model can be arbitrarily worse). A constant model that always\n",
      "        predicts the expected value of y, disregarding the input features,\n",
      "        would get a R^2 score of 0.0.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <r2_score>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape = (n_samples), optional\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : string in ['raw_values', 'uniform_average', 'variance_weighted'] or None or array-like of shape (n_outputs)\n",
      "        \n",
      "            Defines aggregating of multiple output scores.\n",
      "            Array-like value defines weights used to average scores.\n",
      "            Default is \"uniform_average\".\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of scores in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Scores of all outputs are averaged with uniform weight.\n",
      "        \n",
      "            'variance_weighted' :\n",
      "                Scores of all outputs are averaged, weighted by the variances\n",
      "                of each individual output.\n",
      "        \n",
      "            .. versionchanged:: 0.19\n",
      "                Default value of multioutput is 'uniform_average'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        z : float or ndarray of floats\n",
      "            The R^2 score or ndarray of scores if 'multioutput' is\n",
      "            'raw_values'.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is not a symmetric function.\n",
      "        \n",
      "        Unlike most other scores, R^2 score may be negative (it need not actually\n",
      "        be the square of a quantity R).\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Wikipedia entry on the Coefficient of determination\n",
      "                <https://en.wikipedia.org/wiki/Coefficient_of_determination>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import r2_score\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> r2_score(y_true, y_pred)  # doctest: +ELLIPSIS\n",
      "        0.948...\n",
      "        >>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
      "        >>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
      "        >>> r2_score(y_true, y_pred, multioutput='variance_weighted')\n",
      "        ... # doctest: +ELLIPSIS\n",
      "        0.938...\n",
      "        >>> y_true = [1,2,3]\n",
      "        >>> y_pred = [1,2,3]\n",
      "        >>> r2_score(y_true, y_pred)\n",
      "        1.0\n",
      "        >>> y_true = [1,2,3]\n",
      "        >>> y_pred = [2,2,2]\n",
      "        >>> r2_score(y_true, y_pred)\n",
      "        0.0\n",
      "        >>> y_true = [1,2,3]\n",
      "        >>> y_pred = [3,2,1]\n",
      "        >>> r2_score(y_true, y_pred)\n",
      "        -3.0\n",
      "\n",
      "DATA\n",
      "    __ALL__ = ['mean_absolute_error', 'mean_squared_error', 'mean_squared_...\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    string_types = (<type 'basestring'>,)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# conda update scikit-learn \n",
    "\n",
    "help(sklearn.metrics.regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we're going to write a polynomial function that takes an DataFrame and a maximal degree and returns an DataFrame with columns containing the Series to all the powers up to the maximal degree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the hints above complete the following function to create an DataFrame consisting of the powers of an Series up to a specific degree:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use matplotlib to visualize what a polynomial regression looks like on some real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19452</th>\n",
       "      <td>3980300371</td>\n",
       "      <td>20140926T000000</td>\n",
       "      <td>142000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>290.0</td>\n",
       "      <td>20875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98024</td>\n",
       "      <td>47.5308</td>\n",
       "      <td>-121.888</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>22850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15381</th>\n",
       "      <td>2856101479</td>\n",
       "      <td>20140701T000000</td>\n",
       "      <td>276000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>370.0</td>\n",
       "      <td>1801</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>370</td>\n",
       "      <td>0</td>\n",
       "      <td>1923</td>\n",
       "      <td>0</td>\n",
       "      <td>98117</td>\n",
       "      <td>47.6778</td>\n",
       "      <td>-122.389</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1723049033</td>\n",
       "      <td>20140620T000000</td>\n",
       "      <td>245000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>380.0</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98168</td>\n",
       "      <td>47.4810</td>\n",
       "      <td>-122.323</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>15000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18379</th>\n",
       "      <td>1222029077</td>\n",
       "      <td>20141029T000000</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>384.0</td>\n",
       "      <td>213444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98070</td>\n",
       "      <td>47.4177</td>\n",
       "      <td>-122.491</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>224341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>6896300380</td>\n",
       "      <td>20141002T000000</td>\n",
       "      <td>228000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>390.0</td>\n",
       "      <td>5900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>390</td>\n",
       "      <td>0</td>\n",
       "      <td>1953</td>\n",
       "      <td>0</td>\n",
       "      <td>98118</td>\n",
       "      <td>47.5260</td>\n",
       "      <td>-122.261</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>6000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date     price  bedrooms  bathrooms  \\\n",
       "19452  3980300371  20140926T000000  142000.0       0.0       0.00   \n",
       "15381  2856101479  20140701T000000  276000.0       1.0       0.75   \n",
       "860    1723049033  20140620T000000  245000.0       1.0       0.75   \n",
       "18379  1222029077  20141029T000000  265000.0       0.0       0.75   \n",
       "4868   6896300380  20141002T000000  228000.0       0.0       1.00   \n",
       "\n",
       "       sqft_living  sqft_lot floors  waterfront  view     ...      grade  \\\n",
       "19452        290.0     20875      1           0     0     ...          1   \n",
       "15381        370.0      1801      1           0     0     ...          5   \n",
       "860          380.0     15000      1           0     0     ...          5   \n",
       "18379        384.0    213444      1           0     0     ...          4   \n",
       "4868         390.0      5900      1           0     0     ...          4   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat  \\\n",
       "19452         290              0      1963             0    98024  47.5308   \n",
       "15381         370              0      1923             0    98117  47.6778   \n",
       "860           380              0      1963             0    98168  47.4810   \n",
       "18379         384              0      2003             0    98070  47.4177   \n",
       "4868          390              0      1953             0    98118  47.5260   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "19452 -121.888         1620.0     22850.0  \n",
       "15381 -122.389         1340.0      5000.0  \n",
       "860   -122.323         1170.0     15000.0  \n",
       "18379 -122.491         1920.0    224341.0  \n",
       "4868  -122.261         2170.0      6000.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':str, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "sales = pd.read_csv('dataset/kc_house_data.csv', dtype= dtype_dict)\n",
    "sales = sales.sort_values(by=['sqft_living', 'price'])\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-43580.74309447]), array([[ 280.6235679]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm1 = LinearRegression()\n",
    "lm1.fit(sales[[\"sqft_living\"]], sales[[\"price\"]])\n",
    "(lm1.intercept_, lm1.coef_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xd107fd0>,\n",
       " <matplotlib.lines.Line2D at 0x108a78d0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAD8CAYAAABDwhLXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVIV3+Gfkrm/VhvIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8a84cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sales['sqft_living'],sales['price'],'.',\n",
    "        sales['sqft_living'], lm1.predict(sales[['sqft_living']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(sales, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17290"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4323"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-42819.83758135]), array([[ 280.33804071]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm1 = LinearRegression()\n",
    "lm1.fit(train[[\"sqft_living\"]], train[[\"price\"]])\n",
    "(lm1.intercept_, lm1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 77008.25625859]), array([[   312.49068747, -55370.23967698]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2 = LinearRegression()\n",
    "lm2.fit(train[[\"sqft_living\", \"bedrooms\"]], train[[\"price\"]])\n",
    "(lm2.intercept_, lm2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method score in module sklearn.base:\n",
      "\n",
      "score(self, X, y, sample_weight=None) method of sklearn.linear_model.base.LinearRegression instance\n",
      "    Returns the coefficient of determination R^2 of the prediction.\n",
      "    \n",
      "    The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      "    sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      "    sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      "    The best possible score is 1.0 and it can be negative (because the\n",
      "    model can be arbitrarily worse). A constant model that always\n",
      "    predicts the expected value of y, disregarding the input features,\n",
      "    would get a R^2 score of 0.0.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like, shape = (n_samples, n_features)\n",
      "        Test samples.\n",
      "    \n",
      "    y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      "        True values for X.\n",
      "    \n",
      "    sample_weight : array-like, shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    score : float\n",
      "        R^2 of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lm2.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49632873278554884"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm1.score(train[[\"sqft_living\"]], train[[\"price\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50954640231437809"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2.score(train[[\"sqft_living\", \"bedrooms\"]], train[[\"price\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47875695056355583"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm1.score(test[[\"sqft_living\"]], test[[\"price\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49559546535131155"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2.score(test[[\"sqft_living\", \"bedrooms\"]], test[[\"price\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: lm2 is better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67591944552.586945"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test[[\"price\"]], lm2.predict(test[[\"sqft_living\", \"bedrooms\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66193290518.572052"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(train[[\"price\"]], lm2.predict(train[[\"sqft_living\", \"bedrooms\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 714876.68809997]]\n"
     ]
    }
   ],
   "source": [
    "print lm2.predict(test[[\"sqft_living\", \"bedrooms\"]].iloc[0:1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20877</th>\n",
       "      <td>1081330180</td>\n",
       "      <td>20141222T000000</td>\n",
       "      <td>627000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>11830</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2750</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98059</td>\n",
       "      <td>47.4698</td>\n",
       "      <td>-122.121</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>11830.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date     price  bedrooms  bathrooms  \\\n",
       "20877  1081330180  20141222T000000  627000.0       4.0        2.5   \n",
       "\n",
       "       sqft_living  sqft_lot floors  waterfront  view     ...      grade  \\\n",
       "20877       2750.0     11830      2           0     0     ...          9   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat  \\\n",
       "20877        2750              0      2014             0    98059  47.4698   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "20877 -122.121         2310.0     11830.0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[0:1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
